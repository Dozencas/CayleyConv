{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from torch import Tensor\n",
    "from torch.nn import Parameter\n",
    "\n",
    "from torch_geometric.nn import MessagePassing, TopKPooling, global_mean_pool\n",
    "from torch_geometric.utils import degree, get_laplacian\n",
    "from tqdm import trange\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_sparse import SparseTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComplexLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        super(ComplexLinear, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = nn.Parameter(torch.empty((out_features, in_features), dtype=torch.cfloat))\n",
    "        self.bias = nn.Parameter(torch.empty(out_features, dtype=torch.cfloat)) if bias else None\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        nn.init.kaiming_uniform_(self.weight.real, a=math.sqrt(5))\n",
    "        nn.init.kaiming_uniform_(self.weight.imag, a=math.sqrt(5))\n",
    "        if self.bias is not None:\n",
    "            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n",
    "            bound = 1 / math.sqrt(fan_in)\n",
    "            nn.init.uniform_(self.bias, -bound, bound)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return F.linear(input, self.weight, self.bias)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class CayleyConv(MessagePassing):\n",
    "    def __init__(\n",
    "        self,\n",
    "        r: int,\n",
    "        K: int,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        kwargs.setdefault('aggr', 'add')\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        assert r > 0\n",
    "        assert K > 0\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.r = r\n",
    "        self.K = K\n",
    "        self.h = Parameter(torch.empty(1))\n",
    "        self.i = Parameter(torch.tensor(0.+1.j), requires_grad=False)\n",
    "        self.alpha = Parameter(torch.empty(1))\n",
    "        self.real_linear = nn.Linear(in_channels, out_channels, bias=False)\n",
    "        self.complex_linear = ComplexLinear(in_channels * r, out_channels, bias=False)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        super().reset_parameters()\n",
    "        stdv = 1. / math.sqrt(self.in_channels)\n",
    "        self.h.data.uniform_(-stdv, stdv)\n",
    "        self.alpha.data.uniform_(-stdv, stdv)\n",
    "\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x: Tensor,\n",
    "        edge_index: Tensor,\n",
    "    ) -> Tensor:\n",
    "\n",
    "\n",
    "        y_j = x\n",
    "        out_0 = self.real_linear(y_j)\n",
    "        out_r = []\n",
    "\n",
    "        n_nodes = x.size(self.node_dim)\n",
    "        device = edge_index.device\n",
    "        edge_weight = torch.ones(edge_index.size(1), device=device)\n",
    "        row, _ = edge_index\n",
    "        deg = degree(row, n_nodes).to(device)\n",
    "        # Laplacian\n",
    "        l_index, l_weight = get_laplacian(edge_index, edge_weight, normalization=None, num_nodes=n_nodes)\n",
    "        l_weight[l_index[0] == l_index[1]] -= self.alpha\n",
    "\n",
    "        # Jacobi\n",
    "        jacobi = self.calcualte_jacobi(l_index, l_weight)\n",
    "        \n",
    "        # calcualte r polynomials \n",
    "        for j in range(self.r):\n",
    "            \n",
    "            b_j = self.calcualte_b(l_index, l_weight, y_j)\n",
    "            y_j_k = b_j\n",
    "\n",
    "            # K jacobi iteration\n",
    "            for k in range(self.K):\n",
    "                # y_j ^ k+1 = J @ y_j ^ k + b_j\n",
    "                y_j_k = self.propagate(l_index, x=y_j_k, jacobi=jacobi) + b_j\n",
    "            y_j = y_j_k\n",
    "            out_r.append(y_j)\n",
    "        out_r = self.complex_linear(torch.concat(out_r, -1))\n",
    "        out = out_0 + 2 * out_r.real\n",
    "        return out\n",
    "\n",
    "    def message(self, x_j: Tensor, jacobi: Tensor) -> Tensor:\n",
    "        # J Y\n",
    "        return jacobi.view(-1, 1) * x_j\n",
    "    \n",
    "    def calcualte_jacobi(self, l_index, l_weight):\n",
    "        # device\n",
    "        l_row, l_col = l_index\n",
    "\n",
    "        # (hD + iI)^-1 * h\n",
    "        l_dia = l_weight[l_row == l_col]\n",
    "        tmp_left = 1 / (self.h * l_dia + self.i)\n",
    "        tmp_left.masked_fill_(tmp_left == float('inf'), 0.+0.j)\n",
    "        \n",
    "        tmp_right = self.h * l_weight.type(torch.cfloat)\n",
    "        tmp_right[l_row == l_col] = 0.+0.j\n",
    "\n",
    "        jacobi = tmp_left[l_row] * tmp_right\n",
    "        return jacobi\n",
    "\n",
    "    def calcualte_b(self, l_index, l_weight, y_j):\n",
    "        l_row, l_col = l_index\n",
    "\n",
    "        # hL - iI\n",
    "        tmp_right = (l_weight * self.h).type(self.i.dtype)\n",
    "        tmp_right[l_row == l_col] -= self.i\n",
    "\n",
    "        l_dia = l_weight[l_row == l_col]\n",
    "        # (Diag(hL + iI))^-1\n",
    "        tmp_left = 1 / (self.h * l_dia + self.i)\n",
    "        tmp_left.masked_fill_(tmp_left == float('inf'), 0.+0.j)\n",
    "        # (Diag(hL + iI))^-1 (hL - iI)\n",
    "        tmp = tmp_left[l_row] * tmp_right\n",
    "        tmp = torch.sparse_coo_tensor(indices=l_index, values=tmp, device=y_j.device)\n",
    "        return torch.matmul(tmp, y_j.type(torch.cfloat))\n",
    "    \n",
    "class CayleyNet(nn.Module):\n",
    "    def __init__(self, n_conv, r, K, feature_dim, hidden_dim, output_dim):\n",
    "        super(CayleyNet, self).__init__()\n",
    "        convs = []\n",
    "        for i in range(n_conv):\n",
    "            convs.append(CayleyConv(r, K, feature_dim if i == 0 else hidden_dim, hidden_dim))\n",
    "            convs.append(nn.ReLU())\n",
    "        self.convs = nn.ModuleList(convs)\n",
    "        # self.caley_conv = CayleyConv(r, K, feature_dim, hidden_dim)\n",
    "        self.pool = TopKPooling(hidden_dim, ratio=0.9)\n",
    "        self.lin = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        for i in range(0, len(self.convs), 2):\n",
    "            conv = self.convs[i]\n",
    "            relu = self.convs[i+1]\n",
    "            x = conv(x, edge_index)\n",
    "            x = relu(x)\n",
    "\n",
    "        x, edge_index, _, batch, _, _ =  self.pool(x, edge_index)\n",
    "\n",
    "        x = global_mean_pool(x, batch) \n",
    "\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = self.lin(x)\n",
    "        \n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:43<00:00,  4.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.631578947368421 test accuracy\n"
     ]
    }
   ],
   "source": [
    "dataset = TUDataset(root='data/TUDataset', name='MUTAG')\n",
    "DEVICE = 'cpu'\n",
    "\n",
    "model = CayleyNet(n_conv=3, r=5, K=10, feature_dim=7, hidden_dim=64, output_dim=dataset.num_classes).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "train_dataset = dataset[:150]\n",
    "test_dataset = dataset[150:]\n",
    "model.train()\n",
    "for epoch in trange(10):\n",
    "    for data in train_dataset:\n",
    "        data = data.to(DEVICE)\n",
    "        out = model(data.x, data.edge_index) \n",
    "        loss = criterion(out, data.y) \n",
    "        loss.backward() \n",
    "        optimizer.step() \n",
    "        optimizer.zero_grad() \n",
    "\n",
    "\n",
    "model.eval()\n",
    "correct = 0\n",
    "for data in test_dataset:  \n",
    "    data = data.to(DEVICE)\n",
    "    out = model(data.x, data.edge_index)  \n",
    "    pred = out.argmax(dim=1) \n",
    "    correct += int((pred == data.y).sum())  \n",
    "print(\"{} test accuracy\".format(correct / len(test_dataset))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
